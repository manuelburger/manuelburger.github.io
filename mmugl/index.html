<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Multi-modal Graph Learning over UMLS Knowledge Graphs - Manuel Burger</title>
<link rel=stylesheet href=https://manuelburger.ch/css/bootstrap.min.min.css media=screen><meta name=Description content="Clinicians are increasingly looking towards machine learning to gain insights about patient evolutions. We propose a novel approach named Multi-Modal UMLS Graph Learning (MMUGL) for learning meaningful representations of medical concepts using graph neural networks over knowledge graphs based on the unified medical language system. These representations are aggregated to represent entire patient visits and then fed into a sequence model to perform predictions at the granularity of multiple hospital visits of a patient. We improve performance by incorporating prior medical knowledge and considering multiple modalities. We compare our method to existing architectures proposed to learn representations at different granularities on the MIMIC-III dataset and show that our approach outperforms these methods. The results demonstrate the significance of multi-modal medical concept representations based on prior medical knowledge."><meta property="og:url" content="https://manuelburger.ch/mmugl/"><meta property="og:site_name" content="Manuel Burger"><meta property="og:title" content="Multi-modal Graph Learning over UMLS Knowledge Graphs"><meta property="og:description" content="Clinicians are increasingly looking towards machine learning to gain insights about patient evolutions. We propose a novel approach named Multi-Modal UMLS Graph Learning (MMUGL) for learning meaningful representations of medical concepts using graph neural networks over knowledge graphs based on the unified medical language system. These representations are aggregated to represent entire patient visits and then fed into a sequence model to perform predictions at the granularity of multiple hospital visits of a patient. We improve performance by incorporating prior medical knowledge and considering multiple modalities. We compare our method to existing architectures proposed to learn representations at different granularities on the MIMIC-III dataset and show that our approach outperforms these methods. The results demonstrate the significance of multi-modal medical concept representations based on prior medical knowledge."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-09T18:01:40+01:00"><meta property="article:modified_time" content="2023-11-09T18:01:40+01:00"><meta property="article:tag" content="Knowledge Graph"><meta property="article:tag" content="EHR"><meta property="article:tag" content="Time Series"><meta property="article:tag" content="UMLS"><meta property="og:image" content="https://manuelburger.ch/mmugl/architecture_wide_v2.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://manuelburger.ch/mmugl/architecture_wide_v2.png"><meta name=twitter:title content="Multi-modal Graph Learning over UMLS Knowledge Graphs"><meta name=twitter:description content="Clinicians are increasingly looking towards machine learning to gain insights about patient evolutions. We propose a novel approach named Multi-Modal UMLS Graph Learning (MMUGL) for learning meaningful representations of medical concepts using graph neural networks over knowledge graphs based on the unified medical language system. These representations are aggregated to represent entire patient visits and then fed into a sequence model to perform predictions at the granularity of multiple hospital visits of a patient. We improve performance by incorporating prior medical knowledge and considering multiple modalities. We compare our method to existing architectures proposed to learn representations at different granularities on the MIMIC-III dataset and show that our approach outperforms these methods. The results demonstrate the significance of multi-modal medical concept representations based on prior medical knowledge."><meta name=application-name content="My cool site"><meta name=apple-mobile-web-app-title content="My cool site"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://manuelburger.ch/mmugl/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Multi-modal Graph Learning over UMLS Knowledge Graphs","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/manuelburger.ch\/mmugl\/"},"image":[{"@type":"ImageObject","url":"https:\/\/manuelburger.ch\/mmugl\/architecture_wide_v2.png","width":4284,"height":971}],"genre":"posts","keywords":"Knowledge Graph, EHR, Time-Series, UMLS","wordcount":472,"url":"https:\/\/manuelburger.ch\/mmugl\/","datePublished":"2023-11-09T18:01:40+01:00","dateModified":"2023-11-09T18:01:40+01:00","license":"Manuel Burger","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Author"},"description":"Clinicians are increasingly looking towards machine learning to gain insights about patient evolutions. We propose a novel approach named Multi-Modal UMLS Graph Learning (MMUGL) for learning meaningful representations of medical concepts using graph neural networks over knowledge graphs based on the unified medical language system. These representations are aggregated to represent entire patient visits and then fed into a sequence model to perform predictions at the granularity of multiple hospital visits of a patient. We improve performance by incorporating prior medical knowledge and considering multiple modalities. We compare our method to existing architectures proposed to learn representations at different granularities on the MIMIC-III dataset and show that our approach outperforms these methods. The results demonstrate the significance of multi-modal medical concept representations based on prior medical knowledge."}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"light"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"light"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Manuel Burger"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/mbcreate_logo_small512.png data-srcset="/mbcreate_logo_small512.png, /mbcreate_logo_small512.png 1.5x, /mbcreate_logo_small512.png 2x" data-sizes=auto alt=/mbcreate_logo_small512.png title=/mbcreate_logo_small512.png><span class=header-title-pre></span><div style=display:inline;position:relative;top:-4px>Manuel Burger</div></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/about/>About </a><a class=menu-item href=/publications/>Publications </a><a class=menu-item href=/posts/>Posts </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Manuel Burger"><img class="lazyload logo" src=/svg/loading.min.svg data-src=/mbcreate_logo_small512.png data-srcset="/mbcreate_logo_small512.png, /mbcreate_logo_small512.png 1.5x, /mbcreate_logo_small512.png 2x" data-sizes=auto alt=/mbcreate_logo_small512.png title=/mbcreate_logo_small512.png><span class=header-title-pre> </span>Manuel Burger</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/about/ title>About</a><a class=menu-item href=/publications/ title>Publications</a><a class=menu-item href=/posts/ title>Posts</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><main class=main><div class="container-fluid d-flex flex-column"><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Multi-modal Graph Learning over UMLS Knowledge Graphs</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Author</a></span>&nbsp;<span class=post-category>included in <a href=/categories/machine-learning/><i class="far fa-folder fa-fw" aria-hidden=true></i>Machine Learning</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2023-11-09>2023-11-09</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;472 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;3 minutes&nbsp;</div></div><div class=featured-image><img class=lazyload src=/svg/loading.min.svg data-src=/mmugl/architecture_wide_v2.png data-srcset="/mmugl/architecture_wide_v2.png, /mmugl/architecture_wide_v2.png 1.5x, /mmugl/architecture_wide_v2.png 2x" data-sizes=auto alt=/mmugl/architecture_wide_v2.png title="Clinicians are increasingly looking towards machine learning to gain insights about patient evolutions. We propose a novel approach named Multi-Modal UMLS Graph Learning (MMUGL) for learning meaningful representations of medical concepts using graph neural networks over knowledge graphs based on the unified medical language system. These representations are aggregated to represent entire patient visits and then fed into a sequence model to perform predictions at the granularity of multiple hospital visits of a patient. We improve performance by incorporating prior medical knowledge and considering multiple modalities. We compare our method to existing architectures proposed to learn representations at different granularities on the MIMIC-III dataset and show that our approach outperforms these methods. The results demonstrate the significance of multi-modal medical concept representations based on prior medical knowledge."></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#tldr>TL;DR</a></li><li><a href=#citation>Citation</a></li></ul></nav></div></div><div class=content id=content><ul><li><strong>Paper</strong>: <a href=https://proceedings.mlr.press/v225/burger23a.html target=_blank rel="noopener noreffer">https://proceedings.mlr.press/v225/burger23a.html</a></li><li><strong>GitHub</strong>: <a href=https://github.com/ratschlab/mmugl target=_blank rel="noopener noreffer">https://github.com/ratschlab/mmugl</a></li></ul><h2 id=abstract>Abstract</h2><p>Clinicians are increasingly looking towards machine learning to gain insights about patient evolutions. We propose a novel approach named Multi-Modal UMLS Graph Learning (MMUGL) for learning meaningful representations of medical concepts using graph neural networks over knowledge graphs based on the unified medical language system. These representations are aggregated to represent entire patient visits and then fed into a sequence model to perform predictions at the granularity of multiple hospital visits of a patient. We improve performance by incorporating prior medical knowledge and considering multiple modalities. We compare our method to existing architectures proposed to learn representations at different granularities on the MIMIC-III dataset and show that our approach outperforms these methods. The results demonstrate the significance of multi-modal medical concept representations based on prior medical knowledge.</p><h2 id=tldr>TL;DR</h2><p>In this work, published in the Proceedings of Machine Learning (PMLR) and presented at the Machine Learning for Health (ML4H) conference 2023 in New Orleans, we have extracted a large medical knowledge graph from the Unified Medical Language System (UMLS) and trained it using electronic health records (EHR) of patients.</p><p>We show increased predictive performance for a range of clinical prediction tasks such as the onset of heart failure, medication recommendation, and readmission. The performance improvements can be attributed to the inclusion of rich prior knowledge extracted from UMLS, the training on rich multi-modal data (structured and unstructured EHR), and the choice of pretraining.</p><p>Beyond performance improvements we also ascertain the interpretability of our model by using <a href=https://arxiv.org/abs/1903.03894 target=_blank rel="noopener noreffer">GNNExplainer (Ying et al., 2019)</a> to extract subgraphs relevant for the embedding of specific concepts (and as such predictions making use of said concept). The figure below shows the subgraph relevant for the concept of Septic Shock (Sepsis-associated hypotension, UMLS <code>C0036983</code>) extracted using <em>GNNExplainer</em>. Edge thickness corresponds to the edge weight computed by GNNExplainer and the explanation is a reduction of 9932 nodes in a 3-hop neighborhood to 23 related nodes.</p><figure style="padding:.25rem;margin:2rem 0;background-color:#fff"><img style=max-width:100%;width:auto;height:auto src=/mmugl/explanation_graph_septic_shock_hu_8977e663dbfcf7b4.webp width=612 height=400 alt><figcaption><small>Subgraph relevant for the concept of Septic Shock (Sepsis-associated hypotension, UMLS C0036983) extracted using GNNExplainer (Ying et al., 2019). Edge thickness corresponds to the edge weight computed by GNNExplainer and the expla- nation is a reduction of 9932 nodes in a 3-hop neigh- borhood to 23 related nodes.</small></figcaption></figure><h2 id=citation>Citation</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bibtex data-lang=bibtex><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nc>@InProceedings</span><span class=p>{</span><span class=nl>pmlr-v225-burger23a</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>title</span> <span class=p>=</span> 	 <span class=s>{Multi-modal Graph Learning over UMLS Knowledge Graphs}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>author</span> <span class=p>=</span>       <span class=s>{Burger, Manuel and R\&#34;atsch, Gunnar and Kuznetsova, Rita}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>booktitle</span> <span class=p>=</span> 	 <span class=s>{Proceedings of the 3rd Machine Learning for Health Symposium}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>pages</span> <span class=p>=</span> 	 <span class=s>{52--81}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>year</span> <span class=p>=</span> 	 <span class=s>{2023}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>editor</span> <span class=p>=</span> 	 <span class=s>{Hegselmann, Stefan and Parziale, Antonio and Shanmugam, Divya and Tang, Shengpu and Asiedu, Mercy Nyamewaa and Chang, Serina and Hartvigsen, Tom and Singh, Harvineet}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>volume</span> <span class=p>=</span> 	 <span class=s>{225}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>series</span> <span class=p>=</span> 	 <span class=s>{Proceedings of Machine Learning Research}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>month</span> <span class=p>=</span> 	 <span class=s>{10 Dec}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>publisher</span> <span class=p>=</span>    <span class=s>{PMLR}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>pdf</span> <span class=p>=</span> 	 <span class=s>{https://proceedings.mlr.press/v225/burger23a/burger23a.pdf}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>url</span> <span class=p>=</span> 	 <span class=s>{https://proceedings.mlr.press/v225/burger23a.html}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2023-11-09</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://manuelburger.ch/mmugl/ data-title="Multi-modal Graph Learning over UMLS Knowledge Graphs" data-hashtags="Knowledge Graph,EHR,Time-Series,UMLS"><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Linkedin" data-sharer=linkedin data-url=https://manuelburger.ch/mmugl/><i class="fab fa-linkedin fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on WhatsApp" data-sharer=whatsapp data-url=https://manuelburger.ch/mmugl/ data-title="Multi-modal Graph Learning over UMLS Knowledge Graphs" data-web><i class="fab fa-whatsapp fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/knowledge-graph/>Knowledge Graph</a>,&nbsp;<a href=/tags/ehr/>EHR</a>,&nbsp;<a href=/tags/time-series/>Time Series</a>,&nbsp;<a href=/tags/umls/>UMLS</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav></div></div></article></div></main><footer class="footer mt-auto mb-3"><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2022 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank></a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},lightgallery:!0}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>